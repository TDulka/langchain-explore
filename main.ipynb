{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "\n",
    "with open(\"keys.json\", \"r\") as f:\n",
    "    keys = json.load(f)\n",
    "    os.environ['OPENAI_API_KEY'] = keys['openai']\n",
    "    os.environ['COHERE_API_KEY'] = keys['cohere']\n",
    "\n",
    "llm = OpenAI()\n",
    "chat_model = ChatOpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nBrightfoot Socks.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "\n",
    "llm.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ColorThread Collections')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content = text)]\n",
    "\n",
    "chat_model.predict_messages(messages, temperature = 1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good name for a company that makes computers?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "prompt.format(product=\"computers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore programmer\")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "chat_model.predict_messages(chat_prompt.format_messages(input_language=\"English\", output_language=\"French\", text=\"I love programming\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red', 'blue', 'yellow', 'green', 'orange']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "    \n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()\n",
    "\n",
    "chain.invoke({\"text\": \"colors\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning expression language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ChatOpenAIOutput',\n",
       " 'anyOf': [{'$ref': '#/definitions/HumanMessageChunk'},\n",
       "  {'$ref': '#/definitions/AIMessageChunk'},\n",
       "  {'$ref': '#/definitions/ChatMessageChunk'},\n",
       "  {'$ref': '#/definitions/FunctionMessageChunk'},\n",
       "  {'$ref': '#/definitions/SystemMessageChunk'}],\n",
       " 'definitions': {'HumanMessageChunk': {'title': 'HumanMessageChunk',\n",
       "   'description': 'A Human Message chunk.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'},\n",
       "    'is_chunk': {'title': 'Is Chunk',\n",
       "     'default': True,\n",
       "     'enum': [True],\n",
       "     'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'AIMessageChunk': {'title': 'AIMessageChunk',\n",
       "   'description': 'A Message chunk from an AI.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'},\n",
       "    'is_chunk': {'title': 'Is Chunk',\n",
       "     'default': True,\n",
       "     'enum': [True],\n",
       "     'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessageChunk': {'title': 'ChatMessageChunk',\n",
       "   'description': 'A Chat Message chunk.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'},\n",
       "    'is_chunk': {'title': 'Is Chunk',\n",
       "     'default': True,\n",
       "     'enum': [True],\n",
       "     'type': 'boolean'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'FunctionMessageChunk': {'title': 'FunctionMessageChunk',\n",
       "   'description': 'A Function Message chunk.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'is_chunk': {'title': 'Is Chunk',\n",
       "     'default': True,\n",
       "     'enum': [True],\n",
       "     'type': 'boolean'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'SystemMessageChunk': {'title': 'SystemMessageChunk',\n",
       "   'description': 'A System Message chunk.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content', 'type': 'string'},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'},\n",
       "    'is_chunk': {'title': 'Is Chunk',\n",
       "     'default': True,\n",
       "     'enum': [True],\n",
       "     'type': 'boolean'}},\n",
       "   'required': ['content']}}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\", temperature = 0.2)\n",
    "chat_model = ChatOpenAI(temperature= 0)\n",
    "\n",
    "chain = prompt | chat_model\n",
    "\n",
    "chain.input_schema.schema()\n",
    "chain.output_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a dense and enchanting forest, there lived a family of bears. The family consisted of a wise and gentle father bear named Benjamin, a loving and nurturing mother bear named Amelia, and their curious and playful cub named Oliver.\n",
      "\n",
      "The bears lived harmoniously in their cozy den, surrounded by towering trees and a babbling brook. Benjamin, being the protector of the family, would venture out into the forest each day to gather food and ensure their safety. Amelia would spend her days teaching Oliver about the wonders of nature, sharing stories of their ancestors, and instilling in him the values of kindness and respect.\n",
      "\n",
      "One sunny morning, as Benjamin was exploring a new part of the forest, he stumbled upon a lost and frightened baby deer. The poor creature had strayed far from its family and was unable to find its way back. Benjamin's compassionate heart couldn't bear to see the little deer in distress, so he gently picked it up with his strong paws and carried it back to the den.\n",
      "\n",
      "Amelia and Oliver were overjoyed to see the baby deer, and they welcomed it into their family with open arms. They named her Daisy, and she quickly became a cherished member of their bear family. Oliver and Daisy formed an inseparable bond, spending their days frolicking in the meadows and exploring the forest together.\n",
      "\n",
      "As the years passed, the bear family and Daisy grew closer, creating a unique and beautiful friendship. They would often embark on adventures, discovering hidden treasures within the forest and sharing laughter under the moonlit sky. Benjamin, Amelia, Oliver, and Daisy became a symbol of unity and harmony, showing the world that different species could coexist and care for one another.\n",
      "\n",
      "Their story spread far and wide, captivating the hearts of animals and humans alike. People from neighboring villages would visit the forest, hoping to catch a glimpse of the extraordinary bear family and their dear friend Daisy. The bears became ambassadors of compassion and understanding, teaching everyone the importance of embracing diversity and fostering love for all living beings.\n",
      "\n",
      "And so, the family of bears and their beloved deer friend lived happily ever after, leaving a legacy of kindness and acceptance that would forever be remembered in the hearts of those who heard their extraordinary tale."
     ]
    }
   ],
   "source": [
    "async for s in chain.astream({\"topic\": \"bears\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Why don't dogs make good dancers?\\n\\nBecause they have two left feet-paws!\"),\n",
       " AIMessage(content='Sure, here\\'s a cat joke for you:\\n\\nWhy don\\'t cats play poker in the wild?\\n\\nBecause they prefer \"cheetahs\"!')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"dogs\"}, {\"topic\": \"cats\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunLog({'final_output': None,\n",
      " 'id': '1bfd0621-2d8d-4083-a83f-1d9a2ce9a2e6',\n",
      " 'logs': {},\n",
      " 'streamed_output': []})\n",
      "RunLog({'final_output': None,\n",
      " 'id': '1bfd0621-2d8d-4083-a83f-1d9a2ce9a2e6',\n",
      " 'logs': {'Bla': {'end_time': None,\n",
      "                  'final_output': None,\n",
      "                  'id': '215909e2-b81f-4833-a703-328e42626ad3',\n",
      "                  'metadata': {},\n",
      "                  'name': 'Bla',\n",
      "                  'start_time': '2023-10-13T16:30:17.903',\n",
      "                  'streamed_output_str': [],\n",
      "                  'tags': ['map:key:context', 'FAISS'],\n",
      "                  'type': 'retriever'}},\n",
      " 'streamed_output': []})\n",
      "RunLog({'final_output': None,\n",
      " 'id': '1bfd0621-2d8d-4083-a83f-1d9a2ce9a2e6',\n",
      " 'logs': {'Bla': {'end_time': '2023-10-13T16:30:20.898',\n",
      "                  'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                  'id': '215909e2-b81f-4833-a703-328e42626ad3',\n",
      "                  'metadata': {},\n",
      "                  'name': 'Bla',\n",
      "                  'start_time': '2023-10-13T16:30:17.903',\n",
      "                  'streamed_output_str': [],\n",
      "                  'tags': ['map:key:context', 'FAISS'],\n",
      "                  'type': 'retriever'}},\n",
      " 'streamed_output': []})\n",
      "RunLog({'final_output': None,\n",
      " 'id': '1bfd0621-2d8d-4083-a83f-1d9a2ce9a2e6',\n",
      " 'logs': {'Bla': {'end_time': '2023-10-13T16:30:20.898',\n",
      "                  'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                  'id': '215909e2-b81f-4833-a703-328e42626ad3',\n",
      "                  'metadata': {},\n",
      "                  'name': 'Bla',\n",
      "                  'start_time': '2023-10-13T16:30:17.903',\n",
      "                  'streamed_output_str': [],\n",
      "                  'tags': ['map:key:context', 'FAISS'],\n",
      "                  'type': 'retriever'}},\n",
      " 'streamed_output': ['']})\n",
      "RunLog({'final_output': None,\n",
      " 'id': '1bfd0621-2d8d-4083-a83f-1d9a2ce9a2e6',\n",
      " 'logs': {'Bla': {'end_time': '2023-10-13T16:30:20.898',\n",
      "                  'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                  'id': '215909e2-b81f-4833-a703-328e42626ad3',\n",
      "                  'metadata': {},\n",
      "                  'name': 'Bla',\n",
      "                  'start_time': '2023-10-13T16:30:17.903',\n",
      "                  'streamed_output_str': [],\n",
      "                  'tags': ['map:key:context', 'FAISS'],\n",
      "                  'type': 'retriever'}},\n",
      " 'streamed_output': ['', 'H']})\n",
      "RunLog({'final_output': None,\n",
      " 'id': '1bfd0621-2d8d-4083-a83f-1d9a2ce9a2e6',\n",
      " 'logs': {'Bla': {'end_time': '2023-10-13T16:30:20.898',\n",
      "                  'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                  'id': '215909e2-b81f-4833-a703-328e42626ad3',\n",
      "                  'metadata': {},\n",
      "                  'name': 'Bla',\n",
      "                  'start_time': '2023-10-13T16:30:17.903',\n",
      "                  'streamed_output_str': [],\n",
      "                  'tags': ['map:key:context', 'FAISS'],\n",
      "                  'type': 'retriever'}},\n",
      " 'streamed_output': ['', 'H', 'arrison']})\n",
      "RunLog({'final_output': None,\n",
      " 'id': '1bfd0621-2d8d-4083-a83f-1d9a2ce9a2e6',\n",
      " 'logs': {'Bla': {'end_time': '2023-10-13T16:30:20.898',\n",
      "                  'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                  'id': '215909e2-b81f-4833-a703-328e42626ad3',\n",
      "                  'metadata': {},\n",
      "                  'name': 'Bla',\n",
      "                  'start_time': '2023-10-13T16:30:17.903',\n",
      "                  'streamed_output_str': [],\n",
      "                  'tags': ['map:key:context', 'FAISS'],\n",
      "                  'type': 'retriever'}},\n",
      " 'streamed_output': ['', 'H', 'arrison', ' worked']})\n",
      "RunLog({'final_output': None,\n",
      " 'id': '1bfd0621-2d8d-4083-a83f-1d9a2ce9a2e6',\n",
      " 'logs': {'Bla': {'end_time': '2023-10-13T16:30:20.898',\n",
      "                  'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                  'id': '215909e2-b81f-4833-a703-328e42626ad3',\n",
      "                  'metadata': {},\n",
      "                  'name': 'Bla',\n",
      "                  'start_time': '2023-10-13T16:30:17.903',\n",
      "                  'streamed_output_str': [],\n",
      "                  'tags': ['map:key:context', 'FAISS'],\n",
      "                  'type': 'retriever'}},\n",
      " 'streamed_output': ['', 'H', 'arrison', ' worked', ' at']})\n",
      "RunLog({'final_output': None,\n",
      " 'id': '1bfd0621-2d8d-4083-a83f-1d9a2ce9a2e6',\n",
      " 'logs': {'Bla': {'end_time': '2023-10-13T16:30:20.898',\n",
      "                  'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                  'id': '215909e2-b81f-4833-a703-328e42626ad3',\n",
      "                  'metadata': {},\n",
      "                  'name': 'Bla',\n",
      "                  'start_time': '2023-10-13T16:30:17.903',\n",
      "                  'streamed_output_str': [],\n",
      "                  'tags': ['map:key:context', 'FAISS'],\n",
      "                  'type': 'retriever'}},\n",
      " 'streamed_output': ['', 'H', 'arrison', ' worked', ' at', ' Kens']})\n",
      "RunLog({'final_output': None,\n",
      " 'id': '1bfd0621-2d8d-4083-a83f-1d9a2ce9a2e6',\n",
      " 'logs': {'Bla': {'end_time': '2023-10-13T16:30:20.898',\n",
      "                  'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                  'id': '215909e2-b81f-4833-a703-328e42626ad3',\n",
      "                  'metadata': {},\n",
      "                  'name': 'Bla',\n",
      "                  'start_time': '2023-10-13T16:30:17.903',\n",
      "                  'streamed_output_str': [],\n",
      "                  'tags': ['map:key:context', 'FAISS'],\n",
      "                  'type': 'retriever'}},\n",
      " 'streamed_output': ['', 'H', 'arrison', ' worked', ' at', ' Kens', 'ho']})\n",
      "RunLog({'final_output': None,\n",
      " 'id': '1bfd0621-2d8d-4083-a83f-1d9a2ce9a2e6',\n",
      " 'logs': {'Bla': {'end_time': '2023-10-13T16:30:20.898',\n",
      "                  'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                  'id': '215909e2-b81f-4833-a703-328e42626ad3',\n",
      "                  'metadata': {},\n",
      "                  'name': 'Bla',\n",
      "                  'start_time': '2023-10-13T16:30:17.903',\n",
      "                  'streamed_output_str': [],\n",
      "                  'tags': ['map:key:context', 'FAISS'],\n",
      "                  'type': 'retriever'}},\n",
      " 'streamed_output': ['', 'H', 'arrison', ' worked', ' at', ' Kens', 'ho', '.']})\n",
      "RunLog({'final_output': None,\n",
      " 'id': '1bfd0621-2d8d-4083-a83f-1d9a2ce9a2e6',\n",
      " 'logs': {'Bla': {'end_time': '2023-10-13T16:30:20.898',\n",
      "                  'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                  'id': '215909e2-b81f-4833-a703-328e42626ad3',\n",
      "                  'metadata': {},\n",
      "                  'name': 'Bla',\n",
      "                  'start_time': '2023-10-13T16:30:17.903',\n",
      "                  'streamed_output_str': [],\n",
      "                  'tags': ['map:key:context', 'FAISS'],\n",
      "                  'type': 'retriever'}},\n",
      " 'streamed_output': ['',\n",
      "                     'H',\n",
      "                     'arrison',\n",
      "                     ' worked',\n",
      "                     ' at',\n",
      "                     ' Kens',\n",
      "                     'ho',\n",
      "                     '.',\n",
      "                     '']})\n",
      "RunLog({'final_output': {'output': 'Harrison worked at Kensho.'},\n",
      " 'id': '1bfd0621-2d8d-4083-a83f-1d9a2ce9a2e6',\n",
      " 'logs': {'Bla': {'end_time': '2023-10-13T16:30:20.898',\n",
      "                  'final_output': {'documents': [Document(page_content='harrison worked at kensho')]},\n",
      "                  'id': '215909e2-b81f-4833-a703-328e42626ad3',\n",
      "                  'metadata': {},\n",
      "                  'name': 'Bla',\n",
      "                  'start_time': '2023-10-13T16:30:17.903',\n",
      "                  'streamed_output_str': [],\n",
      "                  'tags': ['map:key:context', 'FAISS'],\n",
      "                  'type': 'retriever'}},\n",
      " 'streamed_output': ['',\n",
      "                     'H',\n",
      "                     'arrison',\n",
      "                     ' worked',\n",
      "                     ' at',\n",
      "                     ' Kens',\n",
      "                     'ho',\n",
      "                     '.',\n",
      "                     '']})\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "vectorstore = FAISS.from_texts(['harrison worked at kensho'], embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\"context\": retriever.with_config(run_name = 'Bla'), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | chat_model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "async for chunk in retrieval_chain.astream_log(\"where did harrison work?\", include_names=['Docs', 'Bla'], diff=False):\n",
    "    print(chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableParallel\n",
    "chat_model = ChatOpenAI(temperature=1.6)\n",
    "\n",
    "chain1 = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\") | chat_model\n",
    "chain2 = ChatPromptTemplate.from_template(\"write a short (2 line) poem about {topic}\") | chat_model\n",
    "combined =RunnableParallel(joke=chain1, poem=chain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't bears wear socks?\\nBecause they already have bare paws!\")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"In wild wood's lair,                      Rough paws with clumsy flair,\\nMajestic bears roam.                 Mighty silence carved on their tome.\")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': AIMessage(content='Why don\\'t bears use cellphones?\\n \\nBecause they always break the \"bear\" zones!'),\n",
       " 'poem': AIMessage(content='Majestic and wild, fierce and friendly,\\nBears in the forest, a love ever so pure.')}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQUATION: x^3 + 7 = 12\n",
      "\n",
      "SOLUTION:\n",
      "Subtracting 7 from both sides of the equation, we get:\n",
      "x^3 = 12 - 7\n",
      "x^3 = 5\n",
      "\n",
      "Taking the cube root of both sides, we get:\n",
      "x = ∛5\n",
      "\n",
      "Therefore, the solution to the equation x^3 + 7 = 12 is x = ∛5.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Write out the following equation using algebraic symbols then solve it. Use the format\\n\\nEQUATION:...\\nSOLUTION:...\\n\\n\"),\n",
    "        (\"human\", \"{equation_statement}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "runnable = {\"equation_statement\": RunnablePassthrough()} | prompt | model | StrOutputParser()\n",
    "\n",
    "print(runnable.invoke(\"x raised to the third plus seven equals 12\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQUATION: x^3 + 7 = 12\n",
      "\n",
      "SOLUTION:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runnable = (\n",
    "    {\"equation_statement\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model.bind(stop=\"SOLUTION\")\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(runnable.invoke(\"x raised to the third plus seven equals 12\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"solver\",\n",
    "        \"description\": \"Formulates and solves an equation\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"equation\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The algebraic expression of the equation\",\n",
    "                },\n",
    "                \"solution\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The solution to the equation\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"equation\", \"solution\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'solver', 'arguments': '{\\n\"equation\": \"x^3 + 7 = 12\",\\n\"solution\": \"x = ∛5\"\\n}'}})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Write out the following equation using algebraic symbols then solve it.\"),\n",
    "        (\"human\", \"{equation_statement}\"),\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(model = 'gpt-4', temperature=0).bind(function_call={\"name\": \"solver\"}, functions=functions)\n",
    "\n",
    "runnable = (\n",
    "    {\"equation_statement\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | model\n",
    ")\n",
    "runnable.invoke(\"x raised to the third plus seven equals 12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit error\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI, ChatCohere\n",
    "\n",
    "from unittest.mock import patch\n",
    "from openai.error import RateLimitError\n",
    "\n",
    "openai_llm = ChatOpenAI(max_retries=0)\n",
    "cohere_llm = ChatCohere()\n",
    "llm = openai_llm.with_fallbacks([cohere_llm])\n",
    "\n",
    "with patch('openai.ChatCompletion.create', side_effect=RateLimitError()):\n",
    "    try:\n",
    "        print(openai_llm.invoke(\"Why did the chicken cross the road?\"))\n",
    "    except:\n",
    "        print(\"Hit error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Thank you for your kind words! I\\'m trained to be polite and professional in all my responses.\\n\\nBut sorry, I didn\\'t understand what you mean by \"Why did the kangaroo cross the road?\" Please clarify and I will gladly answer your query.'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You're a nice assistant who always includes a compliment in your response\"),\n",
    "        (\"human\", \"Why did the {animal} cross the road\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | llm\n",
    "with patch('openai.ChatCompletion.create', side_effect=RateLimitError()):\n",
    "    try:\n",
    "         print(chain.invoke({\"animal\": \"kangaroo\"}))\n",
    "    except:\n",
    "        print(\"Hit error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's create a chain with a ChatModel\n",
    "# We add in a string output parser here so the outputs between the two are the same type\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You're a nice assistant who always includes a compliment in your response\"),\n",
    "        (\"human\", \"Why did the {animal} cross the road\"),\n",
    "    ]\n",
    ")\n",
    "# Here we're going to use a bad model name to easily create a chain that will error\n",
    "chat_model = ChatOpenAI(model_name=\"gpt-fake\")\n",
    "bad_chain = chat_prompt | chat_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets create a chain with the normal OpenAI model\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Instructions: You should always include a compliment in your response.\n",
    "\n",
    "Question: Why did the {animal} cross the road?\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "llm = OpenAI()\n",
    "good_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nAnswer: The turtle crossed the road to get to the other side. That's quite a feat! I'm impressed by the turtle's determination and resourcefulness.\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = bad_chain.with_fallbacks([good_chain])\n",
    "chain.invoke({\"animal\": \"turtle\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "from operator import itemgetter\n",
    "\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}\")\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain1 = prompt | model\n",
    "\n",
    "chain = {\n",
    "    \"a\": itemgetter(\"foo\") | RunnableLambda(length_function),\n",
    "    \"b\": {\"text1\": itemgetter(\"foo\"), \"text2\": itemgetter(\"bar\")} | RunnableLambda(multiple_length_function)\n",
    "} | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='3 + 12 = 15')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"foo\": \"bae\", \"bar\": \"bobo\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableConfig\n",
    "\n",
    "def parse_or_fix(text:str, config: RunnableConfig):\n",
    "    fixing_chain = (\n",
    "        ChatPromptTemplate.from_template(\n",
    "            \"Fix the following text:\\n\\n```text\\n{input}\\n```\\nError: {error}\"\n",
    "            \" Don't narrate, just respond with the fixed data.\"\n",
    "        )\n",
    "        | ChatOpenAI()\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            return json.loads(text)\n",
    "        except Exception as e:\n",
    "            text = fixing_chain.invoke({\"input\": text, \"error\": e}, config)\n",
    "    return \"Failed to parse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 75\n",
      "\tPrompt Tokens: 60\n",
      "\tCompletion Tokens: 15\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00011999999999999999\n",
      "{'foo': 'bar', 'baz': '', 'bas': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    res = RunnableLambda(parse_or_fix).invoke(\"{foo: bar, baz:, bas}\", {\"tags\": \"my-tag\", \"callbacks\": [cb]})\n",
    "    print(cb)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = PromptTemplate.from_template(\"\"\"Given the user question below, classify it as either being about `LangChain`, `Anthropic`, or `Other`.\n",
    "                                     \n",
    "Do not respond with more than one word.\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Classification:\"\"\") | ChatCohere() | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"how do I call OpenAI, I wanted to ask where did all the cool people go when they left to start their own AI lab focused on safety. Something about constitutional AI and Dario Amodei\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_chain = PromptTemplate.from_template(\"\"\"You are an expert in langchain. \\\n",
    "Always answer questions starting with \"As Harrison Chase told me\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\") | ChatCohere()\n",
    "\n",
    "anthropic_chain = PromptTemplate.from_template(\"\"\"You are an expert in anthropic. \\\n",
    "Always answer questions starting with \"As Dario Amodei told me\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\") | ChatCohere()\n",
    "\n",
    "general_chain = PromptTemplate.from_template(\"\"\"Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\") | ChatCohere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableBranch\n",
    "\n",
    "branch = RunnableBranch(\n",
    "    (lambda x: \"anthropic\" in x[\"topic\"].lower(), anthropic_chain),\n",
    "    (lambda x: \"langchain\" in x[\"topic\"].lower(), langchain_chain),\n",
    "    general_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The answer is 4.')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain = {\n",
    "    \"topic\": chain,\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | branch\n",
    "\n",
    "full_chain.invoke({\"question\": \"what is 2 + 2?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    if \"anthropic\" in info[\"topic\"].lower():\n",
    "        return anthropic_chain\n",
    "    elif \"langchain\" in info[\"topic\"].lower():\n",
    "        return langchain_chain\n",
    "    else:\n",
    "        return general_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "full_chain = {\n",
    "    \"topic\": chain,\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | RunnableLambda(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As Harrison Chase told me, LangChain is a no-code, drag-and-drop blockchain development platform focused on simplifying the implementation of blockchain use-cases. To use LangChain, users simply need to register on the platform and create a new project. Then, they can start building their blockchain application using the tools and templates available on the platform. Is there any specific aspect of LangChain you'd like to know more about?\")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I simply use LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"joke\",\n",
    "      \"description\": \"A joke\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"setup\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The setup for the joke\"\n",
    "          },\n",
    "          \"punchline\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The punchline for the joke\"\n",
    "          },\n",
    "          \"explanation\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Explanation for the joke\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"setup\", \"punchline\", \"explanation\"]\n",
    "      },\n",
    "    }, \n",
    "    {\n",
    "      \"name\": \"pun\",\n",
    "      \"description\": \"A terrible pun\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"setup\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The setup for the pun\"\n",
    "          },\n",
    "          \"stupid_twist\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The strange twist where the pun appears\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"setup\", \"stupid_twist\"]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {foo}\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "chain = prompt | model.bind(function_call= {\"name\": \"joke\"}, functions= functions)\n",
    "\n",
    "res = chain.invoke({\"foo\": \"bears\"}, config={})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'joke', 'arguments': '{\\n  \"setup\": \"Why don\\'t bears like fast food?\",\\n  \"punchline\": \"Because they can\\'t catch it!\"\\n}'}\n",
      "Tokens Used: 252\n",
      "\tPrompt Tokens: 177\n",
      "\tCompletion Tokens: 75\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.0004155\n",
      "{'name': 'joke', 'arguments': {'setup': \"Why don't bears like fast food?\", 'punchline': \"Because they can't catch it!\"}}\n"
     ]
    }
   ],
   "source": [
    "print(res.additional_kwargs['function_call'])\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    fx = RunnableLambda(parse_or_fix).invoke(res.additional_kwargs['function_call'], {\"tags\": \"my-tag\", \"callbacks\": [cb]})\n",
    "    print(cb)\n",
    "    print(fx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, here's a bear-related joke for you:\\n\\nWhy don't bears wear shoes?\\n\\nBecause they have bear feet!\""
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | StrOutputParser()\n",
    "chain.invoke({\"foo\": \"bears\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Because they're afraid of the net!\""
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser, JsonOutputFunctionsParser\n",
    "\n",
    "chain = (\n",
    "    prompt \n",
    "    | model.bind(function_call= {\"name\": \"pun\"}, functions=functions)\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"stupid_twist\")\n",
    ")\n",
    "\n",
    "chain.invoke({\"foo\": \"fish\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Fish don't like basketball because they are aquatic creatures and are not adapted for playing sports on land. The word 'net' has a double meaning here, referring to both the basketball net and a fishing net.\""
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableMap, RunnablePassthrough\n",
    "\n",
    "map_ = RunnableMap(foo = RunnablePassthrough())\n",
    "\n",
    "chain = (\n",
    "    map_\n",
    "    | prompt\n",
    "    | model.bind(function_call = {\"name\": \"joke\"}, functions=functions)\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"explanation\")\n",
    ")\n",
    "\n",
    "chain.invoke(\"fish\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
